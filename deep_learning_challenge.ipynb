{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the CIFAR10 data\n",
    "The data can be found directly in the package keras (`keras.datasets.cifar10`).\n",
    "\n",
    "```python\n",
    "cifar10 = keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential        # Helper to build a network from a sequence of layers\n",
    "from tensorflow.keras.layers import Dense             # Fully-connected layer\n",
    "from tensorflow.keras.callbacks import EarlyStopping  # To stop training early if val loss stops decreasing\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = tf.keras.datasets.cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train data\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Build the neural network (CNN) to predict the object in the images. Try to do it on your own first before consulting peers or the tutorials on the internet. If you are stuck early, reach out to our mentors who will point you in the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode target values\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_62 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize to range 0-1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape\n",
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1563/1563 [==============================] - 143s 90ms/step - loss: 1.6558 - accuracy: 0.3955 - val_loss: 1.0542 - val_accuracy: 0.6280\n",
      "Epoch 2/50\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.9383 - accuracy: 0.6680 - val_loss: 0.8378 - val_accuracy: 0.7076\n",
      "Epoch 3/50\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.6996 - accuracy: 0.7536 - val_loss: 0.7315 - val_accuracy: 0.7435\n",
      "Epoch 4/50\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.5581 - accuracy: 0.8055 - val_loss: 0.7429 - val_accuracy: 0.7483\n",
      "Epoch 5/50\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.4568 - accuracy: 0.8397 - val_loss: 0.7632 - val_accuracy: 0.7488\n",
      "Epoch 6/50\n",
      "1563/1563 [==============================] - 121s 77ms/step - loss: 0.3605 - accuracy: 0.8745 - val_loss: 0.7721 - val_accuracy: 0.7643\n",
      "Epoch 7/50\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.2907 - accuracy: 0.8990 - val_loss: 0.8541 - val_accuracy: 0.7542\n",
      "Epoch 8/50\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.2477 - accuracy: 0.9122 - val_loss: 0.8548 - val_accuracy: 0.7654\n",
      "Epoch 9/50\n",
      "1563/1563 [==============================] - 140s 90ms/step - loss: 0.2167 - accuracy: 0.9233 - val_loss: 0.9794 - val_accuracy: 0.7409\n",
      "Epoch 10/50\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.1829 - accuracy: 0.9351 - val_loss: 1.0328 - val_accuracy: 0.7559\n",
      "Epoch 11/50\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 0.1636 - accuracy: 0.9441 - val_loss: 1.1026 - val_accuracy: 0.7584\n",
      "Epoch 12/50\n",
      "1563/1563 [==============================] - 128s 82ms/step - loss: 0.1568 - accuracy: 0.9466 - val_loss: 1.1163 - val_accuracy: 0.7502\n",
      "Epoch 13/50\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.1439 - accuracy: 0.9510 - val_loss: 1.1465 - val_accuracy: 0.7571\n",
      "Epoch 14/50\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.1516 - accuracy: 0.9490 - val_loss: 1.1670 - val_accuracy: 0.7586\n",
      "Epoch 15/50\n",
      "1563/1563 [==============================] - 143s 91ms/step - loss: 0.1247 - accuracy: 0.9584 - val_loss: 1.2660 - val_accuracy: 0.7565\n",
      "Epoch 16/50\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1252 - accuracy: 0.9561 - val_loss: 1.1029 - val_accuracy: 0.7697\n",
      "Epoch 17/50\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1198 - accuracy: 0.9593 - val_loss: 1.2428 - val_accuracy: 0.7511\n",
      "Epoch 18/50\n",
      "1563/1563 [==============================] - 129s 83ms/step - loss: 0.1214 - accuracy: 0.9591 - val_loss: 1.2651 - val_accuracy: 0.7603\n",
      "Epoch 19/50\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1103 - accuracy: 0.9629 - val_loss: 1.4432 - val_accuracy: 0.7478\n",
      "Epoch 20/50\n",
      "1563/1563 [==============================] - 133s 85ms/step - loss: 0.1256 - accuracy: 0.9586 - val_loss: 1.3175 - val_accuracy: 0.7592\n",
      "Epoch 21/50\n",
      "1563/1563 [==============================] - 129s 82ms/step - loss: 0.1045 - accuracy: 0.9651 - val_loss: 1.3973 - val_accuracy: 0.7553\n",
      "Epoch 22/50\n",
      "1563/1563 [==============================] - 139s 89ms/step - loss: 0.1069 - accuracy: 0.9649 - val_loss: 1.4520 - val_accuracy: 0.7571\n",
      "Epoch 23/50\n",
      "1563/1563 [==============================] - 135s 86ms/step - loss: 0.1066 - accuracy: 0.9658 - val_loss: 1.4574 - val_accuracy: 0.7544\n",
      "Epoch 24/50\n",
      "1563/1563 [==============================] - 142s 91ms/step - loss: 0.1038 - accuracy: 0.9657 - val_loss: 1.3305 - val_accuracy: 0.7581\n",
      "Epoch 25/50\n",
      "1563/1563 [==============================] - 129s 82ms/step - loss: 0.0889 - accuracy: 0.9702 - val_loss: 1.4935 - val_accuracy: 0.7531\n",
      "Epoch 26/50\n",
      "1563/1563 [==============================] - 138s 88ms/step - loss: 0.1118 - accuracy: 0.9650 - val_loss: 1.5095 - val_accuracy: 0.7664\n",
      "Epoch 27/50\n",
      "1563/1563 [==============================] - 134s 86ms/step - loss: 0.1027 - accuracy: 0.9663 - val_loss: 1.5648 - val_accuracy: 0.7519\n",
      "Epoch 28/50\n",
      "1563/1563 [==============================] - 137s 88ms/step - loss: 0.1079 - accuracy: 0.9663 - val_loss: 1.5516 - val_accuracy: 0.7508\n",
      "Epoch 29/50\n",
      "1563/1563 [==============================] - 136s 87ms/step - loss: 0.0961 - accuracy: 0.9705 - val_loss: 1.6063 - val_accuracy: 0.7545\n",
      "Epoch 30/50\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.1046 - accuracy: 0.9669 - val_loss: 1.6151 - val_accuracy: 0.7634\n",
      "Epoch 31/50\n",
      "1563/1563 [==============================] - 131s 84ms/step - loss: 0.0913 - accuracy: 0.9701 - val_loss: 1.5288 - val_accuracy: 0.7507\n",
      "Epoch 32/50\n",
      "1563/1563 [==============================] - 130s 83ms/step - loss: 0.1000 - accuracy: 0.9677 - val_loss: 1.5818 - val_accuracy: 0.7546\n",
      "Epoch 33/50\n",
      "1563/1563 [==============================] - 134s 85ms/step - loss: 0.1141 - accuracy: 0.9640 - val_loss: 1.5192 - val_accuracy: 0.7590\n",
      "Epoch 34/50\n",
      "1563/1563 [==============================] - 140s 90ms/step - loss: 0.0896 - accuracy: 0.9709 - val_loss: 1.4708 - val_accuracy: 0.7523\n",
      "Epoch 35/50\n",
      "1563/1563 [==============================] - 144s 92ms/step - loss: 0.0863 - accuracy: 0.9723 - val_loss: 1.6560 - val_accuracy: 0.7559\n",
      "Epoch 36/50\n",
      " 909/1563 [================>.............] - ETA: 49s - loss: 0.0904 - accuracy: 0.9715"
     ]
    }
   ],
   "source": [
    "pred = model.fit(train_images, train_labels,\n",
    "                         epochs = 50,\n",
    "                         validation_data = (test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "acc = classifier.evaluate(test_images, test_labels, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
